{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import MonthLocator\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from sklearn.linear_model import LinearRegression as LinearRegression, Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prevoius efforts to build a model to predict ship sink percentages have proved unsucessful. New features have been added to the data set which include time of year (in the form of the depart month and year), average number of U-Boats at sea (from http://www.ibiblio.org/hyperwar/USN/rep/ASW-51/ASW-8.html), prevoius month's sink percentages, time at sea (days), and escort ratio and approximate sighting range (calculated from https://www.ibiblio.org/hyperwar/USN/rep/ASW-51/ASW-10.html). A different notebook will look at feature importance and selection. Additionally, a new approach to predicting convoy saftey will be taken in the form of classifers predicting high vs low risk conovys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complied data of convoys\n",
    "#Routes examined are HX, SC, OB, ON, ONS\n",
    "df = pd.read_csv('Complete_Convoy_Data.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "#df.shape\n",
    "#df.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Ships</th>\n",
       "      <th>Number of Escort Ships</th>\n",
       "      <th>Number of Stragglers</th>\n",
       "      <th>Number of Ships Sunk</th>\n",
       "      <th>Number of Escorts Sunk</th>\n",
       "      <th>Number of Stragglers Sunk</th>\n",
       "      <th>Total Tons of Convoy</th>\n",
       "      <th>Total Tons of Ships Sunk</th>\n",
       "      <th>Overall Sink Percentage</th>\n",
       "      <th>Escort Sink Percentage</th>\n",
       "      <th>Straggler Sink Percentage</th>\n",
       "      <th>Avg Number of U-Boats in Atlantic</th>\n",
       "      <th>Escort Ratio</th>\n",
       "      <th>Time At Sea (Days)</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Previous Month Avg Sink %</th>\n",
       "      <th>Approx. Sighting Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1.174000e+03</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.00000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>1174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.930153</td>\n",
       "      <td>13.799830</td>\n",
       "      <td>0.481261</td>\n",
       "      <td>0.648211</td>\n",
       "      <td>0.030664</td>\n",
       "      <td>0.129472</td>\n",
       "      <td>2.651633e+05</td>\n",
       "      <td>3541.982112</td>\n",
       "      <td>1.246093</td>\n",
       "      <td>0.193813</td>\n",
       "      <td>7.608197</td>\n",
       "      <td>38.711244</td>\n",
       "      <td>0.235122</td>\n",
       "      <td>13.08092</td>\n",
       "      <td>6.573254</td>\n",
       "      <td>1941.795571</td>\n",
       "      <td>1.252933</td>\n",
       "      <td>23.420781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.371021</td>\n",
       "      <td>7.924621</td>\n",
       "      <td>1.421755</td>\n",
       "      <td>1.916348</td>\n",
       "      <td>0.216332</td>\n",
       "      <td>0.476489</td>\n",
       "      <td>1.548845e+05</td>\n",
       "      <td>10508.457265</td>\n",
       "      <td>3.530696</td>\n",
       "      <td>1.324988</td>\n",
       "      <td>25.575738</td>\n",
       "      <td>32.714257</td>\n",
       "      <td>0.092281</td>\n",
       "      <td>5.49256</td>\n",
       "      <td>3.566109</td>\n",
       "      <td>1.676511</td>\n",
       "      <td>1.315712</td>\n",
       "      <td>1.481019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.717500e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.550892e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.173175</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>0.073099</td>\n",
       "      <td>23.671536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.270795e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.238636</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1942.000000</td>\n",
       "      <td>0.812526</td>\n",
       "      <td>23.932372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.353822e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.296166</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1943.000000</td>\n",
       "      <td>1.974096</td>\n",
       "      <td>23.990864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.062596e+06</td>\n",
       "      <td>93502.000000</td>\n",
       "      <td>46.511628</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>4.403733</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Ships  Number of Escort Ships  Number of Stragglers  \\\n",
       "count      1174.000000             1174.000000           1174.000000   \n",
       "mean         56.930153               13.799830              0.481261   \n",
       "std          26.371021                7.924621              1.421755   \n",
       "min           4.000000                0.000000              0.000000   \n",
       "25%          39.000000                7.250000              0.000000   \n",
       "50%          54.000000               14.000000              0.000000   \n",
       "75%          73.000000               19.000000              0.000000   \n",
       "max         191.000000               47.000000             22.000000   \n",
       "\n",
       "       Number of Ships Sunk  Number of Escorts Sunk  \\\n",
       "count           1174.000000             1174.000000   \n",
       "mean               0.648211                0.030664   \n",
       "std                1.916348                0.216332   \n",
       "min                0.000000                0.000000   \n",
       "25%                0.000000                0.000000   \n",
       "50%                0.000000                0.000000   \n",
       "75%                0.000000                0.000000   \n",
       "max               20.000000                4.000000   \n",
       "\n",
       "       Number of Stragglers Sunk  Total Tons of Convoy  \\\n",
       "count                1174.000000          1.174000e+03   \n",
       "mean                    0.129472          2.651633e+05   \n",
       "std                     0.476489          1.548845e+05   \n",
       "min                     0.000000          1.717500e+04   \n",
       "25%                     0.000000          1.550892e+05   \n",
       "50%                     0.000000          2.270795e+05   \n",
       "75%                     0.000000          3.353822e+05   \n",
       "max                     5.000000          1.062596e+06   \n",
       "\n",
       "       Total Tons of Ships Sunk  Overall Sink Percentage  \\\n",
       "count               1174.000000              1174.000000   \n",
       "mean                3541.982112                 1.246093   \n",
       "std                10508.457265                 3.530696   \n",
       "min                    0.000000                 0.000000   \n",
       "25%                    0.000000                 0.000000   \n",
       "50%                    0.000000                 0.000000   \n",
       "75%                    0.000000                 0.000000   \n",
       "max                93502.000000                46.511628   \n",
       "\n",
       "       Escort Sink Percentage  Straggler Sink Percentage  \\\n",
       "count             1174.000000                1174.000000   \n",
       "mean                 0.193813                   7.608197   \n",
       "std                  1.324988                  25.575738   \n",
       "min                  0.000000                   0.000000   \n",
       "25%                  0.000000                   0.000000   \n",
       "50%                  0.000000                   0.000000   \n",
       "75%                  0.000000                   0.000000   \n",
       "max                 16.666667                 100.000000   \n",
       "\n",
       "       Avg Number of U-Boats in Atlantic  Escort Ratio  Time At Sea (Days)  \\\n",
       "count                        1174.000000   1174.000000          1174.00000   \n",
       "mean                           38.711244      0.235122            13.08092   \n",
       "std                            32.714257      0.092281             5.49256   \n",
       "min                             0.000000      0.000000             1.00000   \n",
       "25%                            12.000000      0.173175            10.00000   \n",
       "50%                            30.000000      0.238636            15.00000   \n",
       "75%                            54.000000      0.296166            17.00000   \n",
       "max                           116.000000      0.571429            27.00000   \n",
       "\n",
       "             Month         Year  Previous Month Avg Sink %  \\\n",
       "count  1174.000000  1174.000000                1174.000000   \n",
       "mean      6.573254  1941.795571                   1.252933   \n",
       "std       3.566109     1.676511                   1.315712   \n",
       "min       1.000000  1939.000000                   0.000000   \n",
       "25%       3.000000  1940.000000                   0.073099   \n",
       "50%       7.000000  1942.000000                   0.812526   \n",
       "75%      10.000000  1943.000000                   1.974096   \n",
       "max      12.000000  1945.000000                   4.403733   \n",
       "\n",
       "       Approx. Sighting Range  \n",
       "count             1174.000000  \n",
       "mean                23.420781  \n",
       "std                  1.481019  \n",
       "min                 10.878000  \n",
       "25%                 23.671536  \n",
       "50%                 23.932372  \n",
       "75%                 23.990864  \n",
       "max                 24.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all the cases where a convoy dispersed. Ships were often sunk post dispersal as they lacked the protection of the convoy.\n",
    "#This could skew sink percentages as ships sunk sailing independently (post-dispersion) will be counted as sunk in a convoy.\n",
    "#It is worth noting however, that some of the convoys remaining did disperse, just much closer to land and the likelihood of a ship from a convoy \\\n",
    "# being sunk independently is much lower. \n",
    "\n",
    "df2 = df[df['Time At Sea (Days)'] > 10]\n",
    "#df2.head(-1)\n",
    "#296 Convoys are removed, mostly from the OB series as they dispersed 750 miles from shore \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Ships</th>\n",
       "      <th>Number of Escort Ships</th>\n",
       "      <th>Number of Stragglers</th>\n",
       "      <th>Number of Ships Sunk</th>\n",
       "      <th>Number of Escorts Sunk</th>\n",
       "      <th>Number of Stragglers Sunk</th>\n",
       "      <th>Total Tons of Convoy</th>\n",
       "      <th>Total Tons of Ships Sunk</th>\n",
       "      <th>Overall Sink Percentage</th>\n",
       "      <th>Escort Sink Percentage</th>\n",
       "      <th>Straggler Sink Percentage</th>\n",
       "      <th>Avg Number of U-Boats in Atlantic</th>\n",
       "      <th>Escort Ratio</th>\n",
       "      <th>Time At Sea (Days)</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Previous Month Avg Sink %</th>\n",
       "      <th>Approx. Sighting Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>8.780000e+02</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>878.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>65.453303</td>\n",
       "      <td>16.705011</td>\n",
       "      <td>0.592255</td>\n",
       "      <td>0.664009</td>\n",
       "      <td>0.036446</td>\n",
       "      <td>0.144647</td>\n",
       "      <td>3.048392e+05</td>\n",
       "      <td>3624.879271</td>\n",
       "      <td>1.136934</td>\n",
       "      <td>0.208872</td>\n",
       "      <td>8.085069</td>\n",
       "      <td>47.933941</td>\n",
       "      <td>0.259985</td>\n",
       "      <td>15.969248</td>\n",
       "      <td>6.507973</td>\n",
       "      <td>1942.346241</td>\n",
       "      <td>1.142846</td>\n",
       "      <td>23.852269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.760722</td>\n",
       "      <td>6.700346</td>\n",
       "      <td>1.608142</td>\n",
       "      <td>2.082638</td>\n",
       "      <td>0.240755</td>\n",
       "      <td>0.512812</td>\n",
       "      <td>1.552837e+05</td>\n",
       "      <td>11342.177878</td>\n",
       "      <td>3.610733</td>\n",
       "      <td>1.326105</td>\n",
       "      <td>26.133486</td>\n",
       "      <td>32.675527</td>\n",
       "      <td>0.078474</td>\n",
       "      <td>2.486490</td>\n",
       "      <td>3.523086</td>\n",
       "      <td>1.543273</td>\n",
       "      <td>1.256960</td>\n",
       "      <td>0.553873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.786800e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.900625e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1941.000000</td>\n",
       "      <td>0.073099</td>\n",
       "      <td>23.885472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.714735e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1942.000000</td>\n",
       "      <td>0.578835</td>\n",
       "      <td>23.970888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.908448e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1944.000000</td>\n",
       "      <td>1.921299</td>\n",
       "      <td>23.995145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.062596e+06</td>\n",
       "      <td>93502.000000</td>\n",
       "      <td>46.511628</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>4.403733</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Ships  Number of Escort Ships  Number of Stragglers  \\\n",
       "count       878.000000              878.000000            878.000000   \n",
       "mean         65.453303               16.705011              0.592255   \n",
       "std          23.760722                6.700346              1.608142   \n",
       "min           4.000000                0.000000              0.000000   \n",
       "25%          49.000000               12.000000              0.000000   \n",
       "50%          62.000000               17.000000              0.000000   \n",
       "75%          79.000000               21.000000              1.000000   \n",
       "max         191.000000               47.000000             22.000000   \n",
       "\n",
       "       Number of Ships Sunk  Number of Escorts Sunk  \\\n",
       "count            878.000000              878.000000   \n",
       "mean               0.664009                0.036446   \n",
       "std                2.082638                0.240755   \n",
       "min                0.000000                0.000000   \n",
       "25%                0.000000                0.000000   \n",
       "50%                0.000000                0.000000   \n",
       "75%                0.000000                0.000000   \n",
       "max               20.000000                4.000000   \n",
       "\n",
       "       Number of Stragglers Sunk  Total Tons of Convoy  \\\n",
       "count                 878.000000          8.780000e+02   \n",
       "mean                    0.144647          3.048392e+05   \n",
       "std                     0.512812          1.552837e+05   \n",
       "min                     0.000000          1.786800e+04   \n",
       "25%                     0.000000          1.900625e+05   \n",
       "50%                     0.000000          2.714735e+05   \n",
       "75%                     0.000000          3.908448e+05   \n",
       "max                     5.000000          1.062596e+06   \n",
       "\n",
       "       Total Tons of Ships Sunk  Overall Sink Percentage  \\\n",
       "count                878.000000               878.000000   \n",
       "mean                3624.879271                 1.136934   \n",
       "std                11342.177878                 3.610733   \n",
       "min                    0.000000                 0.000000   \n",
       "25%                    0.000000                 0.000000   \n",
       "50%                    0.000000                 0.000000   \n",
       "75%                    0.000000                 0.000000   \n",
       "max                93502.000000                46.511628   \n",
       "\n",
       "       Escort Sink Percentage  Straggler Sink Percentage  \\\n",
       "count              878.000000                 878.000000   \n",
       "mean                 0.208872                   8.085069   \n",
       "std                  1.326105                  26.133486   \n",
       "min                  0.000000                   0.000000   \n",
       "25%                  0.000000                   0.000000   \n",
       "50%                  0.000000                   0.000000   \n",
       "75%                  0.000000                   0.000000   \n",
       "max                 16.666667                 100.000000   \n",
       "\n",
       "       Avg Number of U-Boats in Atlantic  Escort Ratio  Time At Sea (Days)  \\\n",
       "count                         878.000000    878.000000          878.000000   \n",
       "mean                           47.933941      0.259985           15.969248   \n",
       "std                            32.675527      0.078474            2.486490   \n",
       "min                             0.000000      0.000000           11.000000   \n",
       "25%                            24.000000      0.210526           14.000000   \n",
       "50%                            43.000000      0.258065           16.000000   \n",
       "75%                            66.000000      0.307692           17.000000   \n",
       "max                           116.000000      0.558824           27.000000   \n",
       "\n",
       "            Month         Year  Previous Month Avg Sink %  \\\n",
       "count  878.000000   878.000000                 878.000000   \n",
       "mean     6.507973  1942.346241                   1.142846   \n",
       "std      3.523086     1.543273                   1.256960   \n",
       "min      1.000000  1939.000000                   0.000000   \n",
       "25%      3.000000  1941.000000                   0.073099   \n",
       "50%      6.000000  1942.000000                   0.578835   \n",
       "75%     10.000000  1944.000000                   1.921299   \n",
       "max     12.000000  1945.000000                   4.403733   \n",
       "\n",
       "       Approx. Sighting Range  \n",
       "count              878.000000  \n",
       "mean                23.852269  \n",
       "std                  0.553873  \n",
       "min                 10.878000  \n",
       "25%                 23.885472  \n",
       "50%                 23.970888  \n",
       "75%                 23.995145  \n",
       "max                 24.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Ships</th>\n",
       "      <th>Number of Escort Ships</th>\n",
       "      <th>Number of Stragglers</th>\n",
       "      <th>Total Tons of Convoy</th>\n",
       "      <th>Overall Sink Percentage</th>\n",
       "      <th>Avg Number of U-Boats in Atlantic</th>\n",
       "      <th>Escort Ratio</th>\n",
       "      <th>Time At Sea (Days)</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Previous Month Avg Sink %</th>\n",
       "      <th>Approx. Sighting Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.030458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93630.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.298297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17868.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131859.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.837005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51562.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.916268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>85.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>511572.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>0.098328</td>\n",
       "      <td>23.997420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103961.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>0.098328</td>\n",
       "      <td>23.152177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>82.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280488</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>0.098328</td>\n",
       "      <td>23.996461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>43.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>0.098328</td>\n",
       "      <td>23.784495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>92.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>578428.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>0.098328</td>\n",
       "      <td>23.998766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>878 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number of Ships  Number of Escort Ships  Number of Stragglers  \\\n",
       "0               22.0                     4.0                   0.0   \n",
       "1               19.0                     4.0                   0.0   \n",
       "2                4.0                     0.0                   0.0   \n",
       "3               27.0                     3.0                   0.0   \n",
       "4               13.0                     3.0                   0.0   \n",
       "..               ...                     ...                   ...   \n",
       "873             85.0                    15.0                   0.0   \n",
       "874             30.0                     9.0                   0.0   \n",
       "875             82.0                    23.0                   0.0   \n",
       "876             43.0                    12.0                   0.0   \n",
       "877             92.0                    16.0                   0.0   \n",
       "\n",
       "     Total Tons of Convoy  Overall Sink Percentage  \\\n",
       "0                 99182.0                      0.0   \n",
       "1                 93630.0                      0.0   \n",
       "2                 17868.0                      0.0   \n",
       "3                131859.0                      0.0   \n",
       "4                 51562.0                      0.0   \n",
       "..                    ...                      ...   \n",
       "873              511572.0                      0.0   \n",
       "874              103961.0                      0.0   \n",
       "875              406154.0                      0.0   \n",
       "876              210127.0                      0.0   \n",
       "877              578428.0                      0.0   \n",
       "\n",
       "     Avg Number of U-Boats in Atlantic  Escort Ratio  Time At Sea (Days)  \\\n",
       "0                                  6.0      0.181818                14.0   \n",
       "1                                  6.0      0.210526                17.0   \n",
       "2                                  6.0      0.000000                15.0   \n",
       "3                                  6.0      0.111111                14.0   \n",
       "4                                  3.0      0.230769                14.0   \n",
       "..                                 ...           ...                 ...   \n",
       "873                                0.0      0.176471                15.0   \n",
       "874                                0.0      0.300000                14.0   \n",
       "875                                0.0      0.280488                14.0   \n",
       "876                                0.0      0.279070                13.0   \n",
       "877                                0.0      0.173913                15.0   \n",
       "\n",
       "     Month    Year  Previous Month Avg Sink %  Approx. Sighting Range  \n",
       "0      9.0  1939.0                   0.000000               22.030458  \n",
       "1      9.0  1939.0                   0.000000               21.298297  \n",
       "2      9.0  1939.0                   0.000000               10.878000  \n",
       "3      9.0  1939.0                   0.000000               22.837005  \n",
       "4     10.0  1939.0                   0.000000               18.916268  \n",
       "..     ...     ...                        ...                     ...  \n",
       "873    5.0  1945.0                   0.098328               23.997420  \n",
       "874    5.0  1945.0                   0.098328               23.152177  \n",
       "875    5.0  1945.0                   0.098328               23.996461  \n",
       "876    5.0  1945.0                   0.098328               23.784495  \n",
       "877    5.0  1945.0                   0.098328               23.998766  \n",
       "\n",
       "[878 rows x 12 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping the features that are not needed or give away information\n",
    "df2 = df2.drop(columns=['Convoy Number', 'Number of Ships Sunk', 'Depart_Date', 'Arrival/Dispersal Date', 'Number of Escorts Sunk', \\\n",
    "                         'Number of Stragglers Sunk', 'Total Tons of Ships Sunk', 'Escort Sink Percentage', 'Straggler Sink Percentage'])\n",
    "df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((702, 12), (176, 12), (702,), (176,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Test Split\n",
    "X = np.array(df2.drop(columns=['Overall Sink Percentage']))\n",
    "y = df2['Overall Sink Percentage'].values\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "(Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Fold Cross Validation Function\n",
    "def K_Fold(model, X, y, K, scaler=None, random_state=1945):\n",
    "    kf = KFold(n_splits=K, random_state=random_state, shuffle=True)\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    for idxTrain, idxTest in kf.split(X):\n",
    "        Xtrain = X[idxTrain]\n",
    "        Xtest = X[idxTest]\n",
    "        ytrain = y[idxTrain]\n",
    "        ytest = y[idxTest]\n",
    "        if scaler is not None:\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "        model.fit(Xtrain, ytrain)\n",
    "        train_scores.append(model.score(Xtrain, ytrain))\n",
    "        test_scores.append(model.score(Xtest, ytest))\n",
    "    return train_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Scaler\n",
    "SS = SS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Train Score (R²): 0.4253521196075005\n",
      "Linear Regression Test Score (R²): 0.4182577923968136\n",
      "Linear Regression Coefficients: \n",
      " [ 0.13183566  0.32897265  0.15871105 -0.56979503 -0.07680157 -0.40735971\n",
      " -0.11101439  0.14955117  0.18699064  0.36824446  0.01388311  2.1576393 ]\n",
      "Linear Regression Intercepts: 1.1144472022457077\n",
      "K-Fold Linear Regression Train Score (R²):   0.42692364080872397\n",
      "K-Fold Linear Regression Testing Score (R²): 0.3860106343568942\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "Xtrain_scaled = SS.fit_transform(Xtrain)\n",
    "LR_model = LinearRegression()\n",
    "LR_model.fit(Xtrain_scaled, ytrain)\n",
    "y_predict = LR_model.predict(SS.transform(Xtest))\n",
    "print('Linear Regression Train Score (R\\u00b2):', LR_model.score(Xtrain_scaled, ytrain))\n",
    "print('Linear Regression Test Score (R\\u00b2):', LR_model.score(SS.transform(Xtest), ytest))\n",
    "print('Linear Regression Coefficients: \\n', LR_model.coef_)\n",
    "print('Linear Regression Intercepts:', LR_model.intercept_)\n",
    "train_scores, test_scores = K_Fold(LR_model, X, y, 10, SS)\n",
    "print('K-Fold Linear Regression Train Score (R\\u00b2):  ', np.mean(train_scores))\n",
    "print('K-Fold Linear Regression Testing Score (R\\u00b2):', np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "{'n_estimators': 242}\n",
      "Best Score: -8.343196067549481\n"
     ]
    }
   ],
   "source": [
    "#Cross-validation for optimal n_estimators for use in Random Forest Regressor\n",
    "param_grid = {'n_estimators': [241, 242, 243]}\n",
    "RF_Model = RandomForestRegressor(random_state=1945)\n",
    "grid_search = GridSearchCV(estimator=RF_Model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "best_param = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(best_param)\n",
    "print('Best Score:', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Train Score (R²): 0.9084429952687048\n",
      "Random Forest Regressor Test Score (R²): 0.3737543493369251\n",
      "Random Forest Regressor Mean Squared Error 8.976407583255757\n",
      "K-Fold Random Forest Regressor Train Score (Mean Accuracy): 0.907216313534982\n",
      "K-Fold Random Forest Regressor Test Score (Mean Accuracy): 0.14177016659921754\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Regressor\n",
    "Ran_Forest_Model = RandomForestRegressor(n_estimators=242, random_state=1945) #n_estimators has been optimized using cross-validation\n",
    "Ran_Forest_Model.fit(Xtrain, ytrain)\n",
    "ypredict = Ran_Forest_Model.predict(Xtest)\n",
    "RFR_mse = mean_squared_error(ytest, ypredict)\n",
    "print('Random Forest Regressor Train Score (R\\u00b2):', Ran_Forest_Model.score(Xtrain, ytrain))\n",
    "print('Random Forest Regressor Test Score (R\\u00b2):', Ran_Forest_Model.score(Xtest, ytest))\n",
    "print('Random Forest Regressor Mean Squared Error', RFR_mse)\n",
    "train_scores, test_scores = K_Fold(Ran_Forest_Model, X, y, 10, )\n",
    "print('K-Fold Random Forest Regressor Train Score (Mean Accuracy):', np.mean(train_scores))\n",
    "print('K-Fold Random Forest Regressor Test Score (Mean Accuracy):',np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Train Score (Mean Accuracy): 0.8962808310251966\n",
      "Gradient Boosting Regressor Test Score (Mean Accuracy): 0.2894825640118188\n",
      "Gradient Boosting Regressor Mean Squared Error 10.184332767320253\n",
      "K-Fold Gradient Boosting Train Score (Mean Accuracy): 0.8608164196386469\n",
      "K-Fold Gradient Boosting Test Score (Mean Accuracy): 0.1651481636460374\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Regressor\n",
    "GB_model = GradientBoostingRegressor(random_state=1945)\n",
    "GB_model.fit(Xtrain, ytrain)\n",
    "ypredict = GB_model.predict(Xtest)\n",
    "GB_mse = mean_squared_error(ytest, ypredict)\n",
    "print('Gradient Boosting Regressor Train Score (Mean Accuracy):', GB_model.score(Xtrain, ytrain))\n",
    "print('Gradient Boosting Regressor Test Score (Mean Accuracy):', GB_model.score(Xtest, ytest))\n",
    "print('Gradient Boosting Regressor Mean Squared Error', GB_mse)\n",
    "train_scores, test_scores = K_Fold(GB_model, X, y, 10, )\n",
    "print('K-Fold Gradient Boosting Train Score (Mean Accuracy):', np.mean(train_scores))\n",
    "print('K-Fold Gradient Boosting Test Score (Mean Accuracy):',np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Examining True vs Predicted Sink Rates for the Gradient Boosting Regressor model\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(ytest, ypredict, color='#359af2')\n",
    "plt.xlabel('True Values (Sink Rate)')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('True vs Predicted Values for Convoy Overall Sink Rate')\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(False)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal α Value: 470.0\n"
     ]
    }
   ],
   "source": [
    "#Find Optimal Alpha Value For Ridge Regression\n",
    "a_range = np.linspace(0,600,301) \n",
    "avg_tr_score = []\n",
    "avg_te_score = []\n",
    "for a in a_range:\n",
    "    rid_reg = Ridge(alpha=a, max_iter=10000)\n",
    "    train_scores, test_scores = K_Fold(rid_reg, X, y, 10, SS)\n",
    "    avg_tr_score.append(np.mean(train_scores))\n",
    "    avg_te_score.append(np.mean(test_scores))\n",
    "alpha_max = a_range[np.argmax(avg_te_score)]\n",
    "print('Optimal \\u03B1 Value:', alpha_max)\n",
    "#print(a_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Ridge Regression Train Score (R²): 0.09765564553384128\n",
      "K-Fold Ridge Regression Test Score (R²): 0.06602236493119996\n"
     ]
    }
   ],
   "source": [
    "#Ridge Regression\n",
    "rid_reg = Ridge(alpha=470, max_iter=10000) #Using optimal alpha value\n",
    "train_scores, test_scores = K_Fold(rid_reg, X, y, 10, SS)\n",
    "print('K-Fold Ridge Regression Train Score (R\\u00b2):', np.mean(train_scores))\n",
    "print('K-Fold Ridge Regression Test Score (R\\u00b2):',np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Classifers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Number of Neighbors (Test Score): 20\n"
     ]
    }
   ],
   "source": [
    "#Find Optimal Number of Neighbors for KNN\n",
    "neighbors = np.linspace(1,30,30) \n",
    "neighbors_int = neighbors.astype(int)\n",
    "avg_tr_score = []\n",
    "avg_te_score = []\n",
    "for a in neighbors_int:\n",
    "    knn = KNeighborsRegressor(n_neighbors=a)\n",
    "    train_scores, test_scores = K_Fold(knn, X, y, 10, SS)\n",
    "    avg_tr_score.append(np.mean(train_scores))\n",
    "    avg_te_score.append(np.mean(test_scores))\n",
    "n_neighbors = neighbors_int[np.argmax(avg_te_score)]\n",
    "print('Optimal Number of Neighbors (Test Score):', n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Train Score (Mean Accuracy): 0.16840135446750626\n",
      "KNN Test Score (Mean Accuracy): 0.05183816219137438\n",
      "KNN Mean Squared Error 13.590652648920498\n",
      "K-Fold KNN Train Score (Mean Accuracy): 0.18279714911443246\n",
      "K-Fold KNN Test Score (Mean Accuracy): 0.10012760861380307\n"
     ]
    }
   ],
   "source": [
    "#K-Nearest Neighbors \n",
    "knn = KNeighborsRegressor(n_neighbors=20) #Number of neighbors optimized by best test score. weights='uniform' performs slightly better.\n",
    "Xtrain_scaled = SS.fit_transform(Xtrain)\n",
    "knn.fit(Xtrain_scaled, ytrain)\n",
    "ypredict_knn = knn.predict(SS.transform(Xtest))\n",
    "mse_knn = mean_squared_error(ytest, ypredict_knn)\n",
    "r2_knn = r2_score(ytest, ypredict_knn)\n",
    "print('KNN Train Score (Mean Accuracy):', knn.score(Xtrain_scaled, ytrain))\n",
    "print('KNN Test Score (Mean Accuracy):', knn.score(SS.transform(Xtest), ytest))\n",
    "print('KNN Mean Squared Error', mse_knn)\n",
    "#cm = compare_classes()\n",
    "train_scores, test_scores = K_Fold(knn, X, y, 10, SS)\n",
    "print('K-Fold KNN Train Score (Mean Accuracy):', np.mean(train_scores))\n",
    "print('K-Fold KNN Test Score (Mean Accuracy):',np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Sink Percentage will be changed to a binary target variable with 0 indicating no ships sunk and 1 indicating at least one ship sunk. Predicting a convoy's sink percentage accurately has proved unrealistic, a shift in focus to predicting convoys at risk of losing ships is necessary. There are too many variables that go into convoy attacks that can not be captured as features (evasive maneuvers, night vs day attack, weather, number of U-Boats attacking, etc). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Ships</th>\n",
       "      <th>Number of Escort Ships</th>\n",
       "      <th>Number of Stragglers</th>\n",
       "      <th>Total Tons of Convoy</th>\n",
       "      <th>Overall Sink Percentage</th>\n",
       "      <th>Avg Number of U-Boats in Atlantic</th>\n",
       "      <th>Escort Ratio</th>\n",
       "      <th>Time At Sea (Days)</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Previous Month Avg Sink %</th>\n",
       "      <th>Approx. Sighting Range</th>\n",
       "      <th>High Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.030458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93630.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.298297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17868.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.878000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131859.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.837005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51562.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.916268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Ships  Number of Escort Ships  Number of Stragglers  \\\n",
       "5              22.0                     4.0                   0.0   \n",
       "9              19.0                     4.0                   0.0   \n",
       "13              4.0                     0.0                   0.0   \n",
       "14             27.0                     3.0                   0.0   \n",
       "18             13.0                     3.0                   0.0   \n",
       "\n",
       "    Total Tons of Convoy  Overall Sink Percentage  \\\n",
       "5                99182.0                      0.0   \n",
       "9                93630.0                      0.0   \n",
       "13               17868.0                      0.0   \n",
       "14              131859.0                      0.0   \n",
       "18               51562.0                      0.0   \n",
       "\n",
       "    Avg Number of U-Boats in Atlantic  Escort Ratio  Time At Sea (Days)  \\\n",
       "5                                 6.0      0.181818                14.0   \n",
       "9                                 6.0      0.210526                17.0   \n",
       "13                                6.0      0.000000                15.0   \n",
       "14                                6.0      0.111111                14.0   \n",
       "18                                3.0      0.230769                14.0   \n",
       "\n",
       "    Month    Year  Previous Month Avg Sink %  Approx. Sighting Range  \\\n",
       "5     9.0  1939.0                        0.0               22.030458   \n",
       "9     9.0  1939.0                        0.0               21.298297   \n",
       "13    9.0  1939.0                        0.0               10.878000   \n",
       "14    9.0  1939.0                        0.0               22.837005   \n",
       "18   10.0  1939.0                        0.0               18.916268   \n",
       "\n",
       "    High Risk  \n",
       "5           0  \n",
       "9           0  \n",
       "13          0  \n",
       "14          0  \n",
       "18          0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changing 'Overall Sink Percentage' to a binary value\n",
    "df2['High Risk'] = (df2['Overall Sink Percentage'] > 0).astype(int)\n",
    "X = np.array(df2.drop(columns=['Overall Sink Percentage', 'High Risk']))\n",
    "y = df2['High Risk'].values\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size = 0.8, random_state=1945)\n",
    "df2.head()\n",
    "#(Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Score (Mean Accuracy): 1.0\n",
      "Random Forest Test Score (Mean Accuracy): 0.8579545454545454\n",
      "Random Forest Mean Squared Error 0.14204545454545456\n",
      "Random Forest Classifier Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       141\n",
      "           1       0.78      0.40      0.53        35\n",
      "\n",
      "    accuracy                           0.86       176\n",
      "   macro avg       0.82      0.69      0.72       176\n",
      "weighted avg       0.85      0.86      0.84       176\n",
      "\n",
      "K-Fold Random Forest Classifier Train Score: 1.0\n",
      "K-Fold Random Forest Classifier Test Score: 0.8370950888192269\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "Ran_Forest_Classifier = RandomForestClassifier(random_state=1945)\n",
    "Ran_Forest_Classifier.fit(Xtrain, ytrain)\n",
    "ypredict = Ran_Forest_Classifier.predict(Xtest)\n",
    "Ran_For_mse = mean_squared_error(ytest, ypredict)\n",
    "Classification_Report = classification_report(ytest, ypredict)\n",
    "print('Random Forest Train Score (Mean Accuracy):', Ran_Forest_Classifier.score(Xtrain, ytrain))\n",
    "print('Random Forest Test Score (Mean Accuracy):', Ran_Forest_Classifier.score(Xtest, ytest))\n",
    "print('Random Forest Mean Squared Error', Ran_For_mse)\n",
    "print('Random Forest Classifier Report: \\n', Classification_Report)\n",
    "train_scores, test_scores = K_Fold(Ran_Forest_Classifier, X, y, 10, )\n",
    "print('K-Fold Random Forest Classifier Train Score:', np.mean(train_scores))\n",
    "print('K-Fold Random Forest Classifier Test Score:', np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Score (Mean Accuracy): 0.811965811965812\n",
      "Logistic Regression Test Score (Mean Accuracy): 0.8068181818181818\n",
      "Logistic Regression Mean Squared Error 0.19318181818181818\n",
      "Logistic Regression Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89       141\n",
      "           1       0.60      0.09      0.15        35\n",
      "\n",
      "    accuracy                           0.81       176\n",
      "   macro avg       0.71      0.54      0.52       176\n",
      "weighted avg       0.77      0.81      0.74       176\n",
      "\n",
      "K-Fold Logistic Regression Train Score: 0.8071378962697434\n",
      "K-Fold Logistic Regression Test Score: 0.8075365726227796\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Classifier\n",
    "Log_reg = LogisticRegression()\n",
    "Log_reg.fit(Xtrain, ytrain)\n",
    "y_predict_LR = Log_reg.predict(Xtest)\n",
    "ypredict = Log_reg.predict(Xtest)\n",
    "Log_Reg_mse = mean_squared_error(ytest, ypredict)\n",
    "Classification_Report = classification_report(ytest, ypredict)\n",
    "print('Logistic Regression Train Score (Mean Accuracy):', Log_reg.score(Xtrain, ytrain))\n",
    "print('Logistic Regression Test Score (Mean Accuracy):', Log_reg.score(Xtest, ytest))\n",
    "print('Logistic Regression Mean Squared Error', Log_Reg_mse)\n",
    "print('Logistic Regression Classification Report: \\n', Classification_Report)\n",
    "train_scores, test_scores = K_Fold(Log_reg, X, y, 10, )\n",
    "print('K-Fold Logistic Regression Train Score:', np.mean(train_scores))\n",
    "print('K-Fold Logistic Regression Test Score:', np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Train Score (Mean Accuracy): 0.9487179487179487\n",
      "Gradient Boosting Classifier Test Score (Mean Accuracy): 0.8693181818181818\n",
      "Gradient Boosting Classifier Mean Squared Error 0.13068181818181818\n",
      "Gradient Boosting Classifier Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       141\n",
      "           1       0.80      0.46      0.58        35\n",
      "\n",
      "    accuracy                           0.87       176\n",
      "   macro avg       0.84      0.71      0.75       176\n",
      "weighted avg       0.86      0.87      0.85       176\n",
      "\n",
      "K-Fold Gradient Boosting Classifier Train Score (Mean Accuracy): 0.9383702731680776\n",
      "K-Fold Gradient Boosting Classifier Test Score (Mean Accuracy): 0.8336729362591433\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "GB_model_Classifier = GradientBoostingClassifier(random_state=1945)\n",
    "GB_model_Classifier.fit(Xtrain, ytrain)\n",
    "ypredict = GB_model_Classifier.predict(Xtest)\n",
    "GB_mse_Class = mean_squared_error(ytest, ypredict)\n",
    "print('Gradient Boosting Classifier Train Score (Mean Accuracy):', GB_model_Classifier.score(Xtrain, ytrain))\n",
    "print('Gradient Boosting Classifier Test Score (Mean Accuracy):', GB_model_Classifier.score(Xtest, ytest))\n",
    "print('Gradient Boosting Classifier Mean Squared Error', GB_mse_Class)\n",
    "print('Gradient Boosting Classifier Classification Report: \\n', classification_report(ytest, ypredict))\n",
    "train_scores, test_scores = K_Fold(GB_model_Classifier, X, y, 10, )\n",
    "print('K-Fold Gradient Boosting Classifier Train Score (Mean Accuracy):', np.mean(train_scores))\n",
    "print('K-Fold Gradient Boosting Classifier Test Score (Mean Accuracy):',np.mean(test_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is a much better approach to predicting ship survivability with Gradient Boosting have the best recall for predicting convoys at risk of having at least one ship sunk (0.46). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the train and test data has not been in a time series formart. That means when the models/classifiers are predicting if convoys from 1939 are high or low risk, they are using data from 1940-1945. This method is unrealistic in a real-world application as some of the data used to predict high or low risk would not have occured yet. A time series analysis approach will now be taken to examine high/low risk convoys\n",
    "\n",
    "Time Series Analysis: (Still under development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time Series Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
